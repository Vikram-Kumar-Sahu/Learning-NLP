{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b979170a-08e9-47c0-be91-663ba5619fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"I love teaching for natural language processer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464049c5-ae47-41cd-821d-f64b27df50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'teaching', 'for', 'natural', 'language', 'processer']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96e9c1-40e3-453c-ad3d-9170d3112187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7867be4-fe51-45b5-8d94-cd02a7acea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'teaching', 'for', 'natural', 'language', 'processer']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb93bfd0-1bbc-484a-b58d-35b173f410d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love teach for natur languag process "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for item in tokens:\n",
    "    print(ps.stem(item), end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99b6e41d-5010-4dcf-a58b-dc65b0ee0a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i lov teach for nat langu process "
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "ls = LancasterStemmer()\n",
    "for x in tokens:\n",
    "    print( ls.stem(x),end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eda6ae41-53c9-49e4-b942-d33e94522c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love teach for natur languag process "
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow = SnowballStemmer(\"english\")\n",
    "\n",
    "for i in tokens:\n",
    "    print( snow.stem(i),end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aedb7843-4960-4eb0-b7ae-bd1dceac10a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Finally', 'RB'), ('India', 'NNP'), ('won', 'VBD'), ('the', 'DT'), ('world', 'NN'), ('cup', 'NN')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KIIT0001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\KIIT0001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "print(pos_tag(tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79e78db4-cc04-4e17-96a1-4483dd88f515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wishing', 'VBG'),\n",
       " ('INdigo', 'NNP'),\n",
       " ('diplomacy', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('normalized', 'VBN'),\n",
       " ('soon', 'RB'),\n",
       " ('#', '#')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen=\"Wishing INdigo diplomacy will be normalized soon#\"\n",
    "toks=word_tokenize(sen)\n",
    "pos_tag(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95aa0ced-8fa4-407f-8458-e92ce742c740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('truly', 'RB'),\n",
       " ('amazing', 'JJ'),\n",
       " ('classical', 'JJ'),\n",
       " ('dancer', 'NN')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize(\"She is a truly amazing classical dancer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89955ddc-76c0-4187-ac9f-d0670c67ebc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('true', 'JJ'),\n",
       " ('teacher', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('inspiring', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize(\"A true teacher should be inspiring for all!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa9efc5e-7221-4706-84ab-f05eaa5859c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love teaching for natural language processer "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\KIIT0001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KIIT0001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "for w in tokens:\n",
    "    print(lem.lemmatize(w), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d77a5d09-8e49-4571-9520-dca7ad4b6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbf8f097-95df-4784-98a1-579045db7070",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ne_chunk(pos_tag(tok))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tok' is not defined"
     ]
    }
   ],
   "source": [
    "ne_chunk(pos_tag(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bd639b2-4d89-4881-9a55-88f23e65dba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1693481247.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[69], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    insted of nltk do spacing\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "insted of nltk do spacing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
